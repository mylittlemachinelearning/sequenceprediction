{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import training_data_generator\n",
    "\n",
    "weights_save_name = \"weights_lstm_sequences.hdf5\"\n",
    "\n",
    "model = None\n",
    "model_generated = False\n",
    "cvscores = []\n",
    "\n",
    "# Save and Load dataset from file\n",
    "def save_dataset():\n",
    "    with open(dataset_filename, \"wb\") as fp:\n",
    "        pickle.dump(dataset, fp)\n",
    "#\n",
    "def load_dataset():\n",
    "    global dataset\n",
    "    with open(dataset_filename, \"rb\") as fp:\n",
    "        dataset = pickle.load(fp)\n",
    "\n",
    "# Load weights from file if file exists\n",
    "def load_pretrained_weights():\n",
    "    global model\n",
    "    try:\n",
    "        model.load_weights(weights_save_name)\n",
    "    except:\n",
    "        print('Pre-trained weights do not exist. Please train model to obtain weights')        \n",
    "        \n",
    "def generateSequenceData(pattern_count):\n",
    "    tdg = training_data_generator.training_data_generator(pattern_count)\n",
    "    trainingdata = tdg.produceTrainingSequences()\n",
    "    start_xy =[]\n",
    "    end_xy =[]\n",
    "    for batch in trainingdata:\n",
    "        for pattern in batch:\n",
    "            order = 1\n",
    "            for sequence in pattern:\n",
    "                #start = [order,sequence[0],sequence[1]]\n",
    "                start = [sequence[0],sequence[1]]\n",
    "                start = np.array(start)\n",
    "                start_xy.append(start)\n",
    "                #end = [order,sequence[2],sequence[3]]\n",
    "                end = [sequence[2],sequence[3]]\n",
    "                end = np.array(end)\n",
    "                end_xy.append(end)\n",
    "                order = order +1\n",
    "\n",
    "    start_xy = np.array(start_xy)\n",
    "    start_xy = start_xy.reshape(*start_xy.shape, 1)\n",
    "    end_xy = np.array(end_xy)\n",
    "    end_xy = end_xy.reshape(*end_xy.shape, 1)\n",
    "    return start_xy,end_xy\n",
    "    \n",
    "\n",
    "def generate_and_train_model(start_xy, end_xy, load_weights = False):\n",
    "    global model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=False, input_shape=start_xy.shape[1:]))\n",
    "    model.add(Dense(3, activation='relu'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    callbacks_list = [ModelCheckpoint(weights_save_name, monitor='loss', verbose=1, save_best_only=True, mode='auto', save_weights_only='True')]\n",
    "    model.fit(start_xy,end_xy,batch_size=len(start_xy), epochs=5000,  verbose=2)\n",
    "    if(load_weights==True): load_pretrained_weights()\n",
    "    model_generated = True\n",
    "\n",
    "\n",
    "def generate_and_train_model_with_evaluation(start_xy, end_xy,val_start_xy, val_end_xy, test_start_xy, test_end_xy, load_weights = False):\n",
    "    global model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=False, input_shape=start_xy.shape[1:]))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    #model.compile(loss='mse', optimizer='adam')\n",
    "    model.compile(optimizer=keras.optimizers.RMSprop(),loss=keras.losses.BinaryCrossentropy())\n",
    "    callbacks_list = [ModelCheckpoint(weights_save_name, monitor='loss', verbose=1, save_best_only=True, mode='auto', save_weights_only='True')]\n",
    "    history = model.fit(start_xy,end_xy,batch_size=len(start_xy), epochs=50, validation_data=(val_start_xy, val_end_xy), verbose=2 )\n",
    "    #print(\"history: \", history.history)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(test_start_xy, test_end_xy, verbose=0)\n",
    "    print(\"scores: \",scores)\n",
    "    print(\"predicting for: \")\n",
    "    for i in range(10):\n",
    "        print(\"start: (\",test_start_xy[i][0],\"|\",test_start_xy[i][1],\") end: (\",test_end_xy[i][0],\"|\",test_end_xy[i][1],\")\")\n",
    "    predictions = model.predict(test_start_xy[:10])\n",
    "    print(\"predictions shape:\", predictions.shape)\n",
    "    print(\"predictions:\")\n",
    "    for i in range(10):\n",
    "        print(\"start: (\",test_start_xy[i][0],\"|\",test_start_xy[i][1],\") end: (\",predictions[i][0],\"|\",predictions[i][1],\")\")\n",
    "\n",
    "print(\"start generating sequences\")\n",
    "start_xy,end_xy = generateSequenceData(500)\n",
    "val_start_xy,val_end_xy = generateSequenceData(50)\n",
    "test_start_xy,test_end_xy = generateSequenceData(50)\n",
    "print(\"training and evaluation\")\n",
    "generate_and_train_model_with_evaluation(start_xy, end_xy,val_start_xy, val_end_xy, test_start_xy, test_end_xy)\n",
    "#print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tfnogpu': conda)",
   "language": "python",
   "name": "python37764bittfnogpuconda0654ea235e5d49aaa70c705b96c90962"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
